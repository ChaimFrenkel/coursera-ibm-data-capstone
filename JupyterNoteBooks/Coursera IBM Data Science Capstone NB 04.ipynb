{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# Capstone project for Coursera IBM Data Science\n\nThis will be used for the Coursera IBM Data Science Capstone Project"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Needed for geocoder.\n#!conda install -c conda-forge  geocoder --yes",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Needed for folium\n#!conda install -c conda-forge folium",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# On cognitiveclass.ai: Needed for pd.read_html() \n#!conda install lxml --yes",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\n\nimport requests # library to handle requests\n#import random # library for random number generation\n\n# module to convert an address into latitude and longitude values\nfrom geopy.geocoders import Nominatim\n\n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n# geo plotting library\nimport folium\nimport folium.plugins\n\n# Handle json parsing\nimport json\n\n# Need to sleep for rate limit to foursquare\nfrom time import sleep\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \nprint('Libraries imported.')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Table of Contents\n\n1. Phase 1: Scrape and Transform\n2. Phase 2: Apply Latitude and Longitude\n3. Phase 3: Analyze and Map"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Phase 1: Scrape and Transform"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1. Scrape postal codes and neighborhoods from Wikipedia\nOut of all the tables, the first one with the text \"Borough\" has the data we need."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "postal_codes_url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\npostal_codes_raw = pd.read_html(io=postal_codes_url, match=\"Borough\")[0]    # Grab the first table\npostal_codes_raw.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2. Remove 'Not assigned' entries"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Verify that All Neighbourhoods that are 'Not assigned' also do not have a Borough\nq = postal_codes_raw[(postal_codes_raw['Neighbourhood'] == 'Not assigned') & (postal_codes_raw['Neighbourhood'] != postal_codes_raw['Borough'])]\nq",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "postal_codes_with_borough = postal_codes_raw[postal_codes_raw['Borough'] != 'Not assigned']\npostal_codes_with_borough.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3. Consolidate by Postcode"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Group by columns\nkeycolumns=['Postcode','Borough']\n# Preserve the keys with a multiindex\nmi = pd.MultiIndex.from_frame(postal_codes_with_borough[keycolumns])\n# Create an independent dataframe with the key as the index and only the neighborhood as the column\npostal_codes_indexed = postal_codes_with_borough\\\n                    .copy()\\\n                    .set_index(mi)\\\n                    .drop(columns=keycolumns)\n# Concatenate the neighborhoods with a comma\npostal_codes_clean = postal_codes_indexed\\\n                    .groupby(keycolumns)\\\n                    .aggregate(lambda x: x.str.cat(sep=','))\n# Move the index back to columns\npostal_codes_clean.reset_index(inplace=True,level='Borough')\npostal_codes_clean.sort_values('Postcode',inplace=True)\npostal_codes_clean.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4. And the answer is:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "postal_codes_clean.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Phase 2: Attach geocoding"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Note:** The geocoder package refused to work. Looks like it depends on an API Key that costs money"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1. Get the Geocoded Postal Codes"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#geocode_url = \"https://cocl.us/Geospatial_data\"\n#geodata = pd.read_csv(geocode_url)\n#geodata.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Supplied csv file, unavailable due to problems with code class\nurlGeo_template='http://geogratis.gc.ca/services/geolocation/en/locate?q='\nq = []\nprocessed = 0\nfor p in postal_codes_clean.iterrows():\n    postcode = p[0]\n    url=urlGeo_template + postcode\n    results = requests.get(url).json()\n    if (len(results) > 0):\n        location = results[0]['geometry']['coordinates']\n        q.append([postcode, *location])\n        #print(postcode, location)\n    processed = processed + 1\nprint('Done. Located: ',processed)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "geodata = pd.DataFrame(q,columns=['Postal Code','Longitude','Latitude'])\n#geodata.set_index('Postal Code', inplace=True)\ngeodata.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2. Attach geocoding to Neighbourhoods"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Rename columns, make it an index for the join, sort it\ngeodata_clean =geodata\\\n                .rename(columns={'Postal Code': 'Postcode'})\\\n                .set_index('Postcode')\\\n                .sort_values('Postcode')\ngeodata_clean.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "postal_codes_final = postal_codes_clean.join(geodata_clean, how='left')\npostal_codes_final.reset_index().head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Phase 3: Analyze and Map"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# @hide_cell\nCLIENT_ID = '5FRFUXBNYR421XV1CZRBPDBTYFW0QVCMAXF5PASKCIGBU3I0'\nCLIENT_SECRET= 'I22MHF1CYB5C44H2SRWF0SOQ1KA4DR1LJ0K2RVIYCYAGZQNL'\nOAUTH_TOKEN=\"EILNUTET0HYQEQH155OYZ0MXVMARHZBVUZVJEQJKTULWIOUF\" # User Auth Token",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "VERSION = '20180323'\nLIMIT=100\nRADIUS=1000\nINTENT='browse'\nurl_base = 'https://api.foursquare.com/v2/venues/search?&client_id={}&client_secret={}'\nsecret = [CLIENT_ID,CLIENT_SECRET]\n#url_base = 'https://api.foursquare.com/v2/venues/search?&oauth_token={}'\n#secret = [OAUTH_TOKEN]\n\nurl_template = (url_base + '&v={}&intent={}&limit={}&radius={}').format(\n    *secret,\n    VERSION,\n    INTENT,\n    LIMIT,\n    RADIUS\n    )\nurl_template = url_template + '&ll={},{}'    # &radius={} -- Get as much as will be supplied\nurl_template",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Extract only the primary category, if more than one. If no categories return None.\ndef get_primary_category(categories):\n    for c in categories:\n        if c['primary']:\n            return c['name']\n    return None",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Given description and lat, lon \n# Return the venue id, and associated categories\ndef get_venues_for(postcode, borough, lat, lon):\n    sleep(.5) # personal allows 2 queries/sec.\n    print(postcode, borough, lat, lon,' ',end='')\n    url=url_template.format(lat, lon, 100)\n    #print(url,' ', end='')\n    results = requests.get(url).json()\n    response = results['response']\n    retval = None\n    venues = None\n    if 'venues' in response:\n        venues = response['venues']\n        retval = {'Postcode': postcode, 'Borough': borough, 'Venues': venues}\n        print('Found', len(venues))\n    else:\n        print('No venues returned')\n    return retval",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def venues_to_dataframe(raw_json):\n    wanted = pd.DataFrame()\n    if raw_json != None:\n        nearby_venues = json_normalize(raw_json['Venues'])\n        wanted = nearby_venues[['id','name','categories','location.lat','location.lng','location.distance']]\n        wanted.insert(wanted.shape[1],'category',wanted['categories'].apply(get_primary_category))\n        for k in [ 'Borough', 'Postcode']: # Insert in back order\n            wanted.insert(0, k, raw_json[k])\n\n    wanted.columns = ['Postcode', 'Borough', 'VenueId','name','categories','latitude','longitude','distance','category']\n    return wanted",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Transformation function\n# Given a postal_code row convert to a list of venue ids and category\ndef apply_get_venues(row):\n    #print(row['Postcode'])\n    return get_venues_for(\n                    row['Postcode']     \n                    ,row['Borough']\n                    ,row['Latitude']\n                    ,row['Longitude']\n                  )",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4. Get all the venues and associate categories"
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "# Run through all the postal codes and build up array of results\nprocessed = 0\nrawVenues = []\n\nfor row in postal_codes_final.sort_values(['Latitude','Longitude']).iterrows():\n    raw = get_venues_for(row[0],*row[1][['Borough','Latitude','Longitude']].values)\n    if raw != None:    \n        #print(raw[['id','location.lat','location.lng','name']].sort_values(['id']))\n        rawVenues.append(raw)\n\n    #if processed == 0: print(raw[0])\n    processed = processed + 1\nprint('Done Raw Results: ', processed)\nprint('len(rawVenues)',len(rawVenues))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5.  Save results into flat file to save time when rerunning."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Take the data and save to file\nwith open('venue-data2.json', 'w', encoding='utf-8') as f:\n    json.dump(rawVenues, f, ensure_ascii=False, indent=4)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 6. Now load from flatfile"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "with open('venue-data2.json', 'r', encoding='utf-8') as f:\n    rawVenues = json.load(f)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 7. Extract values from raw json"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Run through all the postal codes and build up array of results\nprocessed = 0\ntodo = []\n\nfor row in rawVenues:\n    raw = venues_to_dataframe(row)\n    todo.append(raw)\n    processed = processed + 1\nprint('Done Venues Results: ', processed)\nvenues = pd.concat(todo,axis='index')\nvenues.drop(columns=['categories'],inplace=True)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "keycolumns=['Postcode','Borough']\nonehot = pd.get_dummies(venues[['category']], prefix=\"\", prefix_sep=\"\")\nwork = pd.concat([venues,onehot], axis=1)\nmi = pd.MultiIndex.from_frame(work[keycolumns])\nwork.set_index(mi, inplace=True)\nwork.drop(columns=keycolumns,inplace=True)\nwork.groupby('Postcode').mean()\nprint(len(venues['VenueId']),len(venues['VenueId'].unique()))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "len(venues['category'].unique())",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "q=geodata.iloc[0]\nq=[q['Latitude'],q['Longitude']]\nprint(type(q))#,q['Latitude'],q['Longitude'])\nfolMap = folium.Map(location=q,zoom_start=9)\nmc = folium.plugins.MarkerCluster()\nfor loc in geodata.iterrows():\n    data = loc[1]\n    folium.CircleMarker([data['Latitude'],data['Longitude']], radius=10, popup=data['Postal Code']).add_to(folMap)\n\ncount=0\nfor loc in venues.iterrows():\n    data=loc[1]\n    # folium display of map fails if there are too many markers.\n    # Using a cluster allows us to increase number, but it still fails when over 9K\n    # \"Randomly\" pick 1 out of 6 locations to map\n    if count % 6 == 0:\n        folium.Marker([data['latitude'],data['longitude']], popup=data['name']).add_to(mc)\n    count = count+1\n    \nfolMap.add_child(mc)\nfolMap",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}